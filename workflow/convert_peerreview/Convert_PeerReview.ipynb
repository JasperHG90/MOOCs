{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Copyright (C) 2015  Leiden University\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see [http://www.gnu.org/licenses/].\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script takes all HTML files in a folder with peer reviewed assignments and stores them in a SQLite database with\n",
    "two tables; \n",
    "\n",
    "  (1) Assignments (full text)\n",
    "  (2) Reviews (scores)\n",
    "  \n",
    "Meta:\n",
    "- Written by: Jasper Ginn\n",
    "- Affiliation: Online learning lab, Leiden Centre for Innovation, Leiden University\n",
    "- Date: 27-05-2015\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "+++ LOAD MODULES +++\n",
    "'''\n",
    "\n",
    "# Create a unique ID for the assignment\n",
    "import uuid\n",
    "# OS for folder mapping\n",
    "import os\n",
    "# Parse HTML\n",
    "from bs4 import BeautifulSoup\n",
    "# Store data in sqlite\n",
    "import sqlite3 as lite\n",
    "# Make reque4sts\n",
    "import urllib2\n",
    "# Regex\n",
    "import re\n",
    "# PDF mining\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from cStringIO import StringIO\n",
    "\n",
    "'''\n",
    "Set encoding settings\n",
    "'''\n",
    "\n",
    "import sys    \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "+++ MAIN FUNCTION +++\n",
    "'''\n",
    "\n",
    "def main(path, dbname, dbpath = '~/desktop', override = \"TRUE\"):\n",
    "    # Sort the db\n",
    "    dbSetup(dbname, dbpath, override = override)\n",
    "    # Foldermapping on level 1\n",
    "    dirs = os.walk(path)\n",
    "    submDir = [x[1] for x in dirs][1]\n",
    "    # Walk\n",
    "    dirs = os.walk(path)\n",
    "    # Get subdir\n",
    "    subDir = [x[1] for x in dirs][0]\n",
    "    # Make directories\n",
    "    fDir = [ \"{}{}/{}\".format(path, subDir[0], nDir)\n",
    "             for nDir in submDir ]\n",
    "    # For each folder . . . \n",
    "    for folder in fDir:\n",
    "        \n",
    "        '''\n",
    "        For each submission\n",
    "        '''\n",
    "        \n",
    "        # Folder mapping on level 2. First, get the submission . . .\n",
    "        dirs = os.walk(folder)\n",
    "        # Get subdir\n",
    "        subd = [x[0] for x in dirs]\n",
    "        PR_sub = \"{}/{}\".format(subd[1], \"fields.html\")\n",
    "        # Extract the information for each submitted PR assignment\n",
    "        \n",
    "        '''\n",
    "        Read html and take out text\n",
    "        '''\n",
    "        \n",
    "        f = urllib2.urlopen(\"file://{}\".format(PR_sub))\n",
    "        soupi = BeautifulSoup(f, \"html.parser\")\n",
    "        # user session ID\n",
    "        uniqID = getID(soupi)\n",
    "        # Hash user ID & use as peer assignment ID\n",
    "        PA_ID = hash(uniqID)\n",
    "        # Check if PDF\n",
    "        res = controlLink(soupi)\n",
    "        if res == True:\n",
    "            #txt = extractText(soupi)\n",
    "            MAIN = soup.find(\"div\", {'class':'field-value'})\n",
    "            # Get link\n",
    "            link = MAIN.find('a').get('href')\n",
    "            # Grab text from PDF\n",
    "            txt = convPDF(str(link))\n",
    "        else:\n",
    "            # Get text from html\n",
    "            txt = extractText(soupi)\n",
    "        # Create values to send to db\n",
    "        vals = [ ( PA_ID,\n",
    "                   uniqID,\n",
    "                   txt.encode(\"utf-8\") ) ]\n",
    "        # Store in database\n",
    "        dbInsert(vals, dbname, \"PR_assignment\", dbpath)\n",
    "        \n",
    "        '''\n",
    "        For each submission, get the evaluations\n",
    "        '''\n",
    "        \n",
    "        # Folder mapping on level 3\n",
    "        evals = []\n",
    "        for edi in subd:\n",
    "            if \"evaluator\" in edi:\n",
    "                fileR = os.listdir(edi)\n",
    "                evals.append(\"{}/{}\".format(edi, fileR[0]))\n",
    "        \n",
    "        # Get evaluations\n",
    "        for evali in evals:\n",
    "            f = urllib2.urlopen(\"file://{}\".format(evali))\n",
    "            soupi = BeautifulSoup(f, \"html.parser\")\n",
    "            # Get user session id\n",
    "            ID = getID(soupi)\n",
    "            # Get scores\n",
    "            Qvals = extractValues(soupi)\n",
    "            # Store in db\n",
    "            vals = [ ( PA_ID,\n",
    "                       uniqID,\n",
    "                       Qvals[0],\n",
    "                       Qvals[1],\n",
    "                       Qvals[2]) ]\n",
    "            # Store in database\n",
    "            dbInsert(vals, dbname, \"PR_review\", dbpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "+++ HELPER FUNCTIONS +++\n",
    "'''\n",
    "\n",
    "'''\n",
    "FUNCTION 1 : Helper function that creates the path for the database. It evaluates whether the path specified by the user ends with\n",
    "'/'. If yes, then paste. If no, then add the '/' to avoid problems.\n",
    "    parameters :\n",
    "        dbname : string\n",
    "            name of the database\n",
    "        path : string\n",
    "            system path where the database is stored. Defaults to '~/desktop'\n",
    "'''\n",
    "\n",
    "def pathMaker(dbname, path):\n",
    "    if path.endswith('/'):\n",
    "        return(path + dbname + '.db')\n",
    "    else:\n",
    "        return(path + '/' + dbname + '.db')\n",
    "    \n",
    "\n",
    "'''\n",
    "FUNCTION 2 : create the SQLite database and commit headers\n",
    "    Parameters :\n",
    "        dbname    : string\n",
    "            name of the database\n",
    "        tablename : string\n",
    "            name of the table in which to store results\n",
    "        path  : string\n",
    "            path to store database. Defaults to '/home/vagrant/Documents/'\n",
    "'''\n",
    "\n",
    "def dbSetup(dbname, path = '~/desktop', override = \"TRUE\"):\n",
    "    # Want to replace the database?\n",
    "    if override == 'TRUE':\n",
    "        pathfile = pathMaker(dbname, path)\n",
    "        con = lite.connect(pathfile)\n",
    "        cur = con.cursor()\n",
    "        # send headers and create table\n",
    "        # Assignments\n",
    "        cur.execute(\"DROP TABLE IF EXISTS PR_assignment;\")\n",
    "        cur.execute(\"CREATE TABLE PR_assignment(assignment_id INT, session_user_id TEXT, assignment TEXT);\")\n",
    "        # review\n",
    "        cur.execute(\"DROP TABLE IF EXISTS PR_review;\")\n",
    "        cur.execute(\"CREATE TABLE PR_review(assignment_id INT, session_user_id TEXT, Q1 INT, Q2 INT, Q3 INT);\")\n",
    "        # Commit\n",
    "        con.commit()\n",
    "        # Destroy\n",
    "        con.close()\n",
    "    else:\n",
    "        print \"Database already exists for path {}. You specified the override option to be {}. The database will be left alone . . . yay!\".format(dbname, path, str(override))\n",
    "\n",
    "'''\n",
    "FUNCTION 3 : Insert results form each page to the database\n",
    "    Parameters :\n",
    "        values_list : list \n",
    "            list of values to send to the database\n",
    "        dbname      : string\n",
    "            name of the database\n",
    "        tablename   : string\n",
    "            name of the table in which to store results\n",
    "        path        : string\n",
    "            path to the database. Defaults to '/home/vagrant/Documents/'\n",
    "'''\n",
    "\n",
    "'''\n",
    "def dbInsert(values_list, dbname, table, path = '~/desktop/'):\n",
    "    # Path to db\n",
    "    pathfile = pathMaker(dbname, path)\n",
    "    # Try connecting and inserting\n",
    "    try:\n",
    "        con = lite.connect(pathfile) \n",
    "        with con:  \n",
    "            # Cursor file\n",
    "            cur = con.cursor()\n",
    "            # choose table\n",
    "            if table == \"PR_assignment\":\n",
    "                # Write values to db\n",
    "                cur.executemany(\"INSERT INTO PR_assignment (assignment_id, session_user_id, assignment) VALUES(?, ?, ?);\", values_list)\n",
    "                # Commit (i.e. save) changes\n",
    "                con.commit()\n",
    "            if table == \"PR_review\":\n",
    "                # Write values to db\n",
    "                cur.executemany(\"INSERT INTO PR_review (assignment_id, session_user_id, Q1, Q2, Q3) VALUES(?, ?, ?, ?, ?);\", values_list)\n",
    "                # Commit (i.e. save) changes\n",
    "                con.commit()\n",
    "        # Close connection\n",
    "        con.close()           \n",
    "    except:\n",
    "        print 'Error while inserting values in the database. Quitting the script now . . . '\n",
    "'''\n",
    "def dbInsert(values_list, dbname, table, path = '~/desktop/'):\n",
    "    # Path to db\n",
    "    pathfile = pathMaker(dbname, path)\n",
    "    # Try connecting and inserting\n",
    "\n",
    "    con = lite.connect(pathfile) \n",
    "    con.text_factory = str\n",
    "    with con:  \n",
    "        # Cursor file\n",
    "        cur = con.cursor()\n",
    "        # choose table\n",
    "        if table == \"PR_assignment\":\n",
    "            # Write values to db\n",
    "            cur.executemany(\"INSERT INTO PR_assignment (assignment_id, session_user_id, assignment) VALUES(?, ?, ?);\", values_list)\n",
    "            # Commit (i.e. save) changes\n",
    "            con.commit()\n",
    "        if table == \"PR_review\":\n",
    "            # Write values to db\n",
    "            cur.executemany(\"INSERT INTO PR_review (assignment_id, session_user_id, Q1, Q2, Q3) VALUES(?, ?, ?, ?, ?);\", values_list)\n",
    "            # Commit (i.e. save) changes\n",
    "            con.commit()\n",
    "    # Close connection\n",
    "    con.close()           \n",
    "\n",
    "        \n",
    "'''\n",
    "FUNCTION 4 : Convert PDF provided via URL to text\n",
    "    parameters : \n",
    "        url : string\n",
    "            url linking to pdf\n",
    "\n",
    "\n",
    "Function is taken from : http://stackoverflow.com/questions/22800100/parsing-a-pdf-via-url-with-python-using-pdfminer\n",
    "'''\n",
    "\n",
    "def convPDF(url): # \n",
    "    # Settings\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    # Unicode\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Open the url provided as an argument to the function and read the content\n",
    "    f = urllib2.urlopen(urllib2.Request(url)).read()\n",
    "    # Cast to StringIO object\n",
    "    fp = StringIO(f)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp,\n",
    "                                  pagenos,\n",
    "                                  maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    str = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return str\n",
    "\n",
    "'''\n",
    "FUNCTION 5 : Get session_user_id from a submitted assignment\n",
    "    parameters :\n",
    "        soup : soup object\n",
    "'''\n",
    "\n",
    "def getID(soup):\n",
    "    # Get metadata\n",
    "    title = soup.find(\"title\").text\n",
    "    # Get \n",
    "    SUI = re.findall('session_user_id: (.*[^,)])', string = title)[0]\n",
    "    # Return\n",
    "    return SUI\n",
    "\n",
    "'''\n",
    "FUNCTION 6 : Check whether a link is provided to a document. If so, then return TRUE.\n",
    "    parameters :\n",
    "        soup : soup object\n",
    "'''\n",
    "\n",
    "def controlLink(soup):\n",
    "    MAIN = soup.find(\"div\", {'class':'field-value'})\n",
    "    # Get all 'a' tags\n",
    "    MIAN = MAIN.findAll('a')\n",
    "    # Get hyperlinks\n",
    "    MIAN_list = [ t.get('href') \n",
    "                 for t in MIAN ]\n",
    "    # Filter if no links present\n",
    "    MIAN_list = [x for x in MIAN_list if x is not None]\n",
    "    # Check if Amazonaws is in any of the links\n",
    "    MIAN_lista = [ \"amazonaws\" in t\n",
    "                  for t in MIAN_list]\n",
    "    # Control\n",
    "    res = True in MIAN_lista\n",
    "    # If find 'a', it means a link to assignment is provided\n",
    "    if res == False:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "'''\n",
    "FUNCTION 7 : Convert bunch of <p> tags to a document\n",
    "    parameters : \n",
    "        soup : soup object\n",
    "'''\n",
    "\n",
    "def extractText(soup):\n",
    "    # Main text\n",
    "    MAIN = soup.find(\"div\", {'class':'field-value'})\n",
    "    # Find all text enclosed in <p> tags\n",
    "    st = MAIN.findAll('p')\n",
    "    # Extract text for each\n",
    "    sd = [ pe.text \n",
    "          for pe in st ]\n",
    "    # Cast into one string\n",
    "    res = \" \".join(sd).replace(\"\\n\", \" \")\n",
    "    # Return\n",
    "    return res\n",
    "\n",
    "'''\n",
    "FUNCTION 8 : Extract peer review values\n",
    "    parameters :\n",
    "        soup : soup object\n",
    "'''\n",
    "\n",
    "def extractValues(soup):\n",
    "    # For values in soup object\n",
    "    field_values = [ int(f.text)\n",
    "                for f in soup.findAll('div', {'class':'field-value'}) ]\n",
    "    # Return\n",
    "    return(field_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/vagrant/PR_ASSIGNMENT_001/\"\n",
    "dbname = \"TEST\"\n",
    "dbpath = \"/home/vagrant/\"\n",
    "override = \"TRUE\"\n",
    "\n",
    "main(path = path, dbname = dbname, dbpath = dbpath, override = override)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
