{
 "metadata": {
  "name": "Convert_PeerReview"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "'''\nThis script takes all HTML files in a folder with peer reviewed assignments and stores them in a SQLite database with\ntwo tables; \n\n  (1) Assignments (full text)\n  (2) Reviews (scores)\n  \nMeta:\n- Written by: Jasper Ginn\n- Affiliation: Online learning lab, Leiden Centre for Innovation, Leiden University\n- Date: 27-05-2015\n\n'''",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "'''\n+++ LOAD MODULES +++\n'''\n\n# Create a unique ID for the assignment\nimport uuid\n# OS for folder mapping\nimport os\n# Parse HTML\nfrom bs4 import BeautifulSoup\n# Store data in sqlite\nimport sqlite3 as lite\n# Make reque4sts\nimport urllib2\n# Regex\nimport re\n# PDF mining\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfpage import PDFPage\nfrom cStringIO import StringIO\n\n'''\nSet encoding settings\n'''\n\nimport sys    \nsys.setdefaultencoding('utf8')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 450
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "'''\n+++ MAIN FUNCTION +++\n'''\n\ndef main(path, dbname, dbpath = '~/desktop', override = \"TRUE\"):\n    # Sort the db\n    dbSetup(dbname, dbpath, override = override)\n    # Foldermapping on level 1\n    dirs = os.walk(path)\n    submDir = [x[1] for x in dirs][1]\n    # Walk\n    dirs = os.walk(path)\n    # Get subdir\n    subDir = [x[1] for x in dirs][0]\n    # Make directories\n    fDir = [ \"{}{}/{}\".format(path, subDir[0], nDir)\n             for nDir in submDir ]\n    # For each folder . . . \n    for folder in fDir:\n        \n        '''\n        For each submission\n        '''\n        \n        # Folder mapping on level 2. First, get the submission . . .\n        dirs = os.walk(folder)\n        # Get subdir\n        subd = [x[0] for x in dirs]\n        PR_sub = \"{}/{}\".format(subd[1], \"fields.html\")\n        # Extract the information for each submitted PR assignment\n        \n        '''\n        Read html and take out text\n        '''\n        \n        f = urllib2.urlopen(\"file://{}\".format(PR_sub))\n        soupi = BeautifulSoup(f, \"html.parser\")\n        # user session ID\n        uniqID = getID(soupi)\n        # Hash user ID & use as peer assignment ID\n        PA_ID = hash(uniqID)\n        # Check if PDF\n        res = controlLink(soupi)\n        if res == True:\n            #txt = extractText(soupi)\n            MAIN = soup.find(\"div\", {'class':'field-value'})\n            # Get link\n            link = MAIN.find('a').get('href')\n            # Grab text from PDF\n            txt = convPDF(str(link))\n        else:\n            # Get text from html\n            txt = extractText(soupi)\n        # Create values to send to db\n        vals = [ ( PA_ID,\n                   uniqID,\n                   txt.encode(\"utf-8\") ) ]\n        # Store in database\n        dbInsert(vals, dbname, \"PR_assignment\", dbpath)\n        \n        '''\n        For each submission, get the evaluations\n        '''\n        \n        # Folder mapping on level 3\n        evals = []\n        for edi in subd:\n            if \"evaluator\" in edi:\n                fileR = os.listdir(edi)\n                evals.append(\"{}/{}\".format(edi, fileR[0]))\n        \n        # Get evaluations\n        for evali in evals:\n            f = urllib2.urlopen(\"file://{}\".format(evali))\n            soupi = BeautifulSoup(f, \"html.parser\")\n            # Get user session id\n            ID = getID(soupi)\n            # Get scores\n            Qvals = extractValues(soupi)\n            # Store in db\n            vals = [ ( PA_ID,\n                       uniqID,\n                       Qvals[0],\n                       Qvals[1],\n                       Qvals[2]) ]\n            # Store in database\n            dbInsert(vals, dbname, \"PR_review\", dbpath)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 513
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "'''\n+++ HELPER FUNCTIONS +++\n'''\n\n'''\nFUNCTION 1 : Helper function that creates the path for the database. It evaluates whether the path specified by the user ends with\n'/'. If yes, then paste. If no, then add the '/' to avoid problems.\n    parameters :\n        dbname : string\n            name of the database\n        path : string\n            system path where the database is stored. Defaults to '~/desktop'\n'''\n\ndef pathMaker(dbname, path):\n    if path.endswith('/'):\n        return(path + dbname + '.db')\n    else:\n        return(path + '/' + dbname + '.db')\n    \n\n'''\nFUNCTION 2 : create the SQLite database and commit headers\n    Parameters :\n        dbname    : string\n            name of the database\n        tablename : string\n            name of the table in which to store results\n        path  : string\n            path to store database. Defaults to '/home/vagrant/Documents/'\n'''\n\ndef dbSetup(dbname, path = '~/desktop', override = \"TRUE\"):\n    # Want to replace the database?\n    if override == 'TRUE':\n        pathfile = pathMaker(dbname, path)\n        con = lite.connect(pathfile)\n        cur = con.cursor()\n        # send headers and create table\n        # Assignments\n        cur.execute(\"DROP TABLE IF EXISTS PR_assignment;\")\n        cur.execute(\"CREATE TABLE PR_assignment(assignment_id INT, session_user_id TEXT, assignment TEXT);\")\n        # review\n        cur.execute(\"DROP TABLE IF EXISTS PR_review;\")\n        cur.execute(\"CREATE TABLE PR_review(assignment_id INT, session_user_id TEXT, Q1 INT, Q2 INT, Q3 INT);\")\n        # Commit\n        con.commit()\n        # Destroy\n        con.close()\n    else:\n        print \"Database already exists for path {}. You specified the override option to be {}. The database will be left alone . . . yay!\".format(dbname, path, str(override))\n\n'''\nFUNCTION 3 : Insert results form each page to the database\n    Parameters :\n        values_list : list \n            list of values to send to the database\n        dbname      : string\n            name of the database\n        tablename   : string\n            name of the table in which to store results\n        path        : string\n            path to the database. Defaults to '/home/vagrant/Documents/'\n'''\n\n'''\ndef dbInsert(values_list, dbname, table, path = '~/desktop/'):\n    # Path to db\n    pathfile = pathMaker(dbname, path)\n    # Try connecting and inserting\n    try:\n        con = lite.connect(pathfile) \n        with con:  \n            # Cursor file\n            cur = con.cursor()\n            # choose table\n            if table == \"PR_assignment\":\n                # Write values to db\n                cur.executemany(\"INSERT INTO PR_assignment (assignment_id, session_user_id, assignment) VALUES(?, ?, ?);\", values_list)\n                # Commit (i.e. save) changes\n                con.commit()\n            if table == \"PR_review\":\n                # Write values to db\n                cur.executemany(\"INSERT INTO PR_review (assignment_id, session_user_id, Q1, Q2, Q3) VALUES(?, ?, ?, ?, ?);\", values_list)\n                # Commit (i.e. save) changes\n                con.commit()\n        # Close connection\n        con.close()           \n    except:\n        print 'Error while inserting values in the database. Quitting the script now . . . '\n'''\ndef dbInsert(values_list, dbname, table, path = '~/desktop/'):\n    # Path to db\n    pathfile = pathMaker(dbname, path)\n    # Try connecting and inserting\n\n    con = lite.connect(pathfile) \n    con.text_factory = str\n    with con:  \n        # Cursor file\n        cur = con.cursor()\n        # choose table\n        if table == \"PR_assignment\":\n            # Write values to db\n            cur.executemany(\"INSERT INTO PR_assignment (assignment_id, session_user_id, assignment) VALUES(?, ?, ?);\", values_list)\n            # Commit (i.e. save) changes\n            con.commit()\n        if table == \"PR_review\":\n            # Write values to db\n            cur.executemany(\"INSERT INTO PR_review (assignment_id, session_user_id, Q1, Q2, Q3) VALUES(?, ?, ?, ?, ?);\", values_list)\n            # Commit (i.e. save) changes\n            con.commit()\n    # Close connection\n    con.close()           \n\n        \n'''\nFUNCTION 4 : Convert PDF provided via URL to text\n    parameters : \n        url : string\n            url linking to pdf\n\n\nFunction is taken from : http://stackoverflow.com/questions/22800100/parsing-a-pdf-via-url-with-python-using-pdfminer\n'''\n\ndef convPDF(url): # \n    # Settings\n    rsrcmgr = PDFResourceManager()\n    retstr = StringIO()\n    # Unicode\n    codec = 'utf-8'\n    laparams = LAParams()\n    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n    # Open the url provided as an argument to the function and read the content\n    f = urllib2.urlopen(urllib2.Request(url)).read()\n    # Cast to StringIO object\n    fp = StringIO(f)\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    password = \"\"\n    maxpages = 0\n    caching = True\n    pagenos = set()\n    for page in PDFPage.get_pages(fp,\n                                  pagenos,\n                                  maxpages=maxpages,\n                                  password=password,\n                                  caching=caching,\n                                  check_extractable=True):\n        interpreter.process_page(page)\n    fp.close()\n    device.close()\n    str = retstr.getvalue()\n    retstr.close()\n    return str\n\n'''\nFUNCTION 5 : Get session_user_id from a submitted assignment\n    parameters :\n        soup : soup object\n'''\n\ndef getID(soup):\n    # Get metadata\n    title = soup.find(\"title\").text\n    # Get \n    SUI = re.findall('session_user_id: (.*[^,)])', string = title)[0]\n    # Return\n    return SUI\n\n'''\nFUNCTION 6 : Check whether a link is provided to a document. If so, then return TRUE.\n    parameters :\n        soup : soup object\n'''\n\ndef controlLink(soup):\n    MAIN = soup.find(\"div\", {'class':'field-value'})\n    # Get all 'a' tags\n    MIAN = MAIN.findAll('a')\n    # Get hyperlinks\n    MIAN_list = [ t.get('href') \n                 for t in MIAN ]\n    # Filter if no links present\n    MIAN_list = [x for x in MIAN_list if x is not None]\n    # Check if Amazonaws is in any of the links\n    MIAN_lista = [ \"amazonaws\" in t\n                  for t in MIAN_list]\n    # Control\n    res = True in MIAN_lista\n    # If find 'a', it means a link to assignment is provided\n    if res == False:\n        return False\n    else:\n        return True\n    \n'''\nFUNCTION 7 : Convert bunch of <p> tags to a document\n    parameters : \n        soup : soup object\n'''\n\ndef extractText(soup):\n    # Main text\n    MAIN = soup.find(\"div\", {'class':'field-value'})\n    # Find all text enclosed in <p> tags\n    st = MAIN.findAll('p')\n    # Extract text for each\n    sd = [ pe.text \n          for pe in st ]\n    # Cast into one string\n    res = \" \".join(sd).replace(\"\\n\", \" \")\n    # Return\n    return res\n\n'''\nFUNCTION 8 : Extract peer review values\n    parameters :\n        soup : soup object\n'''\n\ndef extractValues(soup):\n    # For values in soup object\n    field_values = [ int(f.text)\n                for f in soup.findAll('div', {'class':'field-value'}) ]\n    # Return\n    return(field_values)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "path = \"/home/vagrant/PR_ASSIGNMENT_001/\"\ndbname = \"TEST\"\ndbpath = \"/home/vagrant/\"\noverride = \"TRUE\"\n\nmain(path = path, dbname = dbname, dbpath = dbpath, override = override)",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}